{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import datetime\n",
    "from sys import getsizeof,path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "path.append(\"../src\")\n",
    "from Splines import CentripetalCatmullRomSpline_splitControls,Spline\n",
    "import Cases\n",
    "from Population import ImportPopulation\n",
    "from ModelParams import ObservedData,ModelParam\n",
    "\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "\n",
    "\n",
    "theano.config.gcc_cxxflags = \"-Wno-c++11-narrowing\"\n",
    "\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-comedy",
   "metadata": {},
   "source": [
    "# Simple Example - recover control Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-suicide",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "old = False\n",
    "\n",
    "coords = {\"cpx\":np.array([1,2,3,4,5,6,7],\"float64\"),\"space\":np.linspace(2.01,6.99,128,\"float64\")}\n",
    "test_control = np.array([1,3,2,1,2,2,3],\"float64\")\n",
    "test_spline = Spline(coords[\"cpx\"],tt.cast(test_control,\"float64\"))\n",
    "\n",
    "t1 = time.time()\n",
    "test_values = test_spline.EvaluateAt(coords[\"space\"],old=old).eval()\n",
    "test_values += np.random.normal(0, .1, coords[\"space\"].shape[0])\n",
    "t2 = time.time()\n",
    "print(\"Test values in %.3fs\"%(t2-t1))\n",
    "\n",
    "plt.plot(coords[\"space\"],test_values,color=\"tab:red\")\n",
    "plt.plot(coords[\"cpx\"],test_control,\"rx\")\n",
    "\n",
    "with pm.Model(coords=coords) as model:\n",
    "    \n",
    "    sigma_control = pm.Lognormal(\"sigma_control\",mu=tt.log(2),sigma=1.)\n",
    "    \n",
    "    est_control = pm.Normal(\"est_control\",mu=0,sigma=sigma_control,dims=(\"cpx\"))\n",
    "    est_control = tt.exp(tt.cumsum(est_control))\n",
    "    \n",
    "    est_spline = Spline(coords[\"cpx\"],est_control)\n",
    "    est_values = est_spline.EvaluateAt(coords[\"space\"],old=old)\n",
    "    \n",
    "    pm.Deterministic(\"est_values\",est_values)\n",
    "\n",
    "    sigma_obs = pm.HalfCauchy(name=\"sigma_obs\",beta=2)\n",
    "    pm.StudentT(\"est\",nu=4,sigma=tt.abs_(est_values+1.)**.5 * sigma_obs,mu=est_values,observed=test_values)\n",
    "    \n",
    "    trace = pm.sample(init=\"advi\",return_inferencedata=True,tune=200,draws=200,cores=4,chains=4,max_treedepth=12,target_accept=.95)\n",
    "\n",
    "t3 = time.time()\n",
    "print(\"Compiled and Sampled in %.3f\"%(t3-t2))\n",
    "\n",
    "q = trace.posterior[\"est_values\"].quantile((0.5,.05,.95),[\"chain\",\"draw\"])\n",
    "plt.plot(coords[\"space\"],q[0],color=\"tab:blue\")\n",
    "plt.fill_between(coords[\"space\"],q[1],q[2],alpha=.1,color=\"tab:blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace.posterior[\"est_control\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace.posterior[\"sigma_control\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace.posterior[\"sigma_obs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-guarantee",
   "metadata": {},
   "source": [
    "# SEIR Model with R_eff from Spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {}\n",
    "if False:\n",
    "    coords[\"cpx\"] = np.linspace(0,70,8,\"float64\")\n",
    "    coords[\"space\"] = np.linspace(8,51,44,\"float64\")\n",
    "else:\n",
    "    coords[\"cpx\"] = pd.date_range(datetime.date(2020,1,30),datetime.date(2020,5,16),freq=\"SM\")\n",
    "    coords[\"space\"] = pd.date_range(datetime.date(2020,2,20),datetime.date(2020,4,5),freq=\"D\")\n",
    "\n",
    "print(coords[\"cpx\"],len(coords[\"cpx\"]))\n",
    "print(coords[\"space\"],len(coords[\"space\"]))\n",
    "\n",
    "rtest_control = np.array([3,5,6,2,.9,.9,1.1,1.2],\"float64\")\n",
    "rtest_spline = Spline(coords[\"cpx\"],tt.cast(rtest_control,\"float64\"))\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "rtest_tvalues = rtest_spline.EvaluateAt(coords[\"space\"])\n",
    "rtest_values = rtest_tvalues.eval()\n",
    "rtest_values += np.random.normal(0, .1, coords[\"space\"].shape[0])\n",
    "t2 = time.time()\n",
    "print(\"Test values in %.3fs\"%(t2-t1))\n",
    "\n",
    "print(rtest_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_lognormal(x, mu, sigma):\n",
    "# Limit to prevent NANs\n",
    "    x = tt.clip(x,1e-9,1e12)\n",
    "    sigma = tt.clip(sigma,1e-9,1e12)\n",
    "    mu = tt.clip(mu,1e-9,1e12)\n",
    "    \n",
    "    distr = 1/x * tt.exp( -( (tt.log(x) - mu) ** 2) / (2 * sigma ** 2))\n",
    "    return distr / (tt.sum(distr, axis=0) + 1e-12)\n",
    "\n",
    "def SEIR_model(N, imported_t,Reff_t, median_incubation,sigma_incubation,l=32):\n",
    "    N = tt.cast(N,'float64')\n",
    "    beta = tt_lognormal(tt.arange(l), tt.log(median_incubation), sigma_incubation)\n",
    "    \n",
    "    # Dirty hack to prevent nan - seems not needed if priors are better\n",
    " #   beta = tt.alloc(0,l)\n",
    "  #  beta = tt.set_subtensor(beta[tt.clip(tt.cast(median_incubation,'int32'),1,l-2)],1)\n",
    "     \n",
    "    Reff_t = tt.as_tensor_variable(Reff_t)\n",
    "    imported_t = tt.as_tensor_variable(imported_t)\n",
    "\n",
    "    def new_day(Reff_at_t,imported_at_t,infected,E_t,beta,N):\n",
    "        f = E_t / N\n",
    "     #   f = 1\n",
    "        new = imported_at_t + tt.dot(infected,beta) * Reff_at_t * f\n",
    "        new = tt.clip(new,0,N)\n",
    "     \n",
    "        infected = tt.roll(infected,1,0)\n",
    "        infected = tt.set_subtensor(infected[:1],new,inplace=False)\n",
    "        E_t = tt.clip(E_t-new,0,E_t)\n",
    "#        E_t = E_t-new\n",
    "        return new,infected,E_t\n",
    "    \n",
    "    outputs_info = [None,np.zeros(l),N]\n",
    "    infected_t,updates = theano.scan(fn=new_day,\n",
    "                                     sequences=[Reff_t,imported_t],\n",
    "                                     outputs_info=outputs_info,\n",
    "                                     non_sequences=[beta,N],\n",
    "                                     profile=False)\n",
    "                                     \n",
    "    return infected_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = tt.zeros_like(rtest_tvalues)\n",
    "initial = tt.set_subtensor(initial[:5],tt.cast([6,6,4,2,1],\"float64\"))\n",
    "\n",
    "new,infected,E_t = SEIR_model(83e8,initial,rtest_values,6,.3)\n",
    "\n",
    "new_infected = new.eval()\n",
    "new_infected += np.random.normal(0, .3, coords[\"space\"].shape[0])\n",
    "\n",
    "print(rtest_values)\n",
    "print(new_infected)\n",
    "\n",
    "plt.plot(coords[\"space\"],rtest_values)\n",
    "plt.plot(coords[\"space\"],new_infected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-lunch",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "old = False\n",
    "t2 = time.time()\n",
    "\n",
    "with pm.Model(coords=coords) as model:\n",
    "    \n",
    "    sigma_control = pm.Lognormal(\"sigma_control\",mu=tt.log(2),sigma=1.)\n",
    "    \n",
    "    est_control = pm.Normal(\"est_control\",mu=0,sigma=sigma_control,dims=(\"cpx\"))\n",
    "    est_control = tt.exp(tt.cumsum(est_control))\n",
    "    \n",
    "    est_spline = Spline(coords[\"cpx\"],est_control)\n",
    "    est_values = est_spline.EvaluateAt(coords[\"space\"],old=old)\n",
    "    \n",
    "    est_new,est_infected,est_E_t = SEIR_model(83e8,initial,est_values,6,.3)\n",
    "    \n",
    "    pm.Deterministic(\"est_control_sum\",est_control)\n",
    "    pm.Deterministic(\"est_values\",est_values)\n",
    "    pm.Deterministic(\"est_new\",est_new)\n",
    "\n",
    "    sigma_obs = pm.HalfCauchy(name=\"sigma_obs\",beta=2)\n",
    "    pm.StudentT(\"est\",nu=4,sigma=tt.abs_(est_new+1.)**.5 * sigma_obs,mu=est_new,observed=new_infected)\n",
    "    \n",
    "    trace = pm.sample(init=\"advi\",return_inferencedata=True,tune=200,draws=200,cores=4,chains=4,max_treedepth=12,target_accept=.95)\n",
    "\n",
    "t3 = time.time()\n",
    "print(\"Compiled and Sampled in %.3f\"%(t3-t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = trace.posterior[\"est_control_sum\"].quantile((0.5,.05,.95),[\"chain\",\"draw\"])\n",
    "\n",
    "plt.plot(coords[\"cpx\"],q[0])\n",
    "plt.fill_between(coords[\"cpx\"],q[1],q[2],alpha=.1)\n",
    "\n",
    "print(q)\n",
    "plt.plot(coords[\"cpx\"],rtest_control,\"rx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace.posterior[\"est_control\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = trace.posterior[\"est_new\"].quantile((0.5,.05,.95),[\"chain\",\"draw\"])\n",
    "\n",
    "plt.plot(coords[\"space\"],q[0])\n",
    "plt.fill_between(coords[\"space\"],q[1],q[2],alpha=.1)\n",
    "\n",
    "print(q)\n",
    "plt.plot(coords[\"space\"],new_infected,\"rx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace.posterior[\"sigma_control\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace.posterior[\"sigma_obs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-intranet",
   "metadata": {},
   "source": [
    "# Hierachical SurvStat\n",
    "Run Age,location stratified SEIR and compare with weekly reporting from SurvStat\n",
    "\n",
    "- seasonality (12 monthly values) --> global R_0\n",
    "- per week: walk representing gradual change in measures\n",
    "- per BL: monthly diff (measures might be fast)\n",
    "- per AG: monthly diff\n",
    "\n",
    "100 weeks * 16 BL * 5 AG = 8k weekly values, 56k entries in R_eff-matrix (daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately not feasable even with HalfCauchy instead of Lognormal for the hyperparameter.\n",
    "4-10x more time spend outside of sampling, than inside if number of days surpasses ~100 days. ~1h pre+post "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "old = False\n",
    "\n",
    "start = datetime.datetime(2020,2,15)\n",
    "end = datetime.datetime(2021,8,1)\n",
    "\n",
    "coords = {}\n",
    "\n",
    "coords[\"seasons_12month\"] = range(1,13)\n",
    "coords[\"days\"] = pd.date_range(start,end,freq=\"D\")\n",
    "coords[\"weeks\"] = pd.date_range(start,end,freq=\"W\")\n",
    "coords[\"months\"] = pd.date_range(start,end,freq=\"M\")\n",
    "coords[\"BL\"] = range(1,17)\n",
    "coords[\"AG\"] = np.array([0,20,40,60,80])\n",
    "\n",
    "print(len(coords[\"days\"]))\n",
    "\n",
    "observed_cases = Cases.ObservedCasesFromSurvstat(\"210713\")\n",
    "observed_cases.RenameAxes({\"age\":\"AG\"})\n",
    "pop = ObservedData(\"population\",ImportPopulation().sum(\"sex\")[\"31.12.2019\"] * 1000.)\n",
    "pop.RenameAxes({\"age\":\"AG\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-recruitment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(coords=coords) as model:\n",
    "\n",
    "    # Seasonality\n",
    "    season_sigma = pm.HalfCauchy(\"season_sigma\",beta=1.)\n",
    "    season_control = pm.Lognormal(\"season_control\",mu=tt.log(1.),sigma=season_sigma,dims=(\"seasons_12month\"))\n",
    "    season_control24m = tt.concatenate([season_control,season_control])\n",
    "    season_range24m = pd.date_range(start=datetime.datetime(2020,1,1),end=datetime.datetime(2022,1,1),freq=\"M\")\n",
    "    season_spline = Spline(season_range24m,season_control24m)\n",
    "    \n",
    "    season_daily = season_spline.EvaluateAt(coords[\"days\"],old=old)\n",
    "    \n",
    "    # weekly walk\n",
    "    measures_sigma = pm.HalfCauchy(\"measures_sigma\",beta=1.)\n",
    "    measures_value = pm.Normal(\"measures_value\",mu=0.,sigma=measures_sigma,dims=(\"weeks\"))\n",
    "    measures_walk = tt.cumsum(measures_value,axis=0)\n",
    "    measures_spline = Spline(coords[\"weeks\"],measures_walk)\n",
    "    \n",
    "    measures_daily = measures_spline.EvaluateAt(coords[\"days\"],old=old)\n",
    "    pm.Deterministic(\"measures_daily\",measures_daily)\n",
    "    \n",
    "    # Monthly Age-Diff\n",
    "    if True:\n",
    "        age_sigma = pm.HalfCauchy(\"age_sigma\",beta=1.)\n",
    "        age_value = pm.Normal(\"age_value\",mu=0.,sigma=age_sigma,dims=(\"AG\",\"months\",))\n",
    "        age_walk = tt.cumsum(age_value,axis=1)\n",
    "        age_spline = Spline(coords[\"months\"],age_walk)\n",
    "    \n",
    "        age_daily = age_spline.EvaluateAt(coords[\"days\"],old=old).dimshuffle(1,0,'x')\n",
    "    else:\n",
    "        age_daily = tt.cast(0.,\"float64\").reshape((1,1,))\n",
    "    pm.Deterministic(\"age_daily\",age_daily)\n",
    "    \n",
    "    # Monthly BL-Diff \n",
    "    if True:\n",
    "        BL_sigma = pm.HalfCauchy(\"BL_sigma\",beta=1.)\n",
    "        BL_value = pm.Normal(\"BL_value\",mu=0.,sigma=BL_sigma,dims=(\"BL\",\"months\",))\n",
    "        BL_walk = tt.cumsum(BL_value,axis=1)\n",
    "        BL_spline = Spline(coords[\"months\"],BL_walk)\n",
    "        BL_daily = BL_spline.EvaluateAt(coords[\"days\"],old=old).dimshuffle(1,'x',0)\n",
    "    else:\n",
    "        BL_daily = tt.cast(0,\"float64\").reshape((1,1,))\n",
    "    pm.Deterministic(\"BL_daily\",BL_daily)\n",
    "    \n",
    "    modsum = measures_daily.dimshuffle(0,'x','x')+age_daily+BL_daily\n",
    "    R_eff = season_daily.reshape((len(coords[\"days\"]),1,1,))*tt.exp(modsum)\n",
    "    pm.Deterministic(\"R_eff\",R_eff)\n",
    "    \n",
    "    # Initial Cases\n",
    "    initial_length = 14\n",
    "    initial_mag = pm.Lognormal(\"initial\",mu=tt.log(10.),sigma=1.,dims=(\"AG\",\"BL\"))\n",
    "    initial = tt.zeros_like(R_eff)\n",
    "    imported = tt.set_subtensor(initial[:initial_length],tt.stack([initial_mag]*initial_length))\n",
    "    \n",
    "    # population\n",
    "    imp_coord = OrderedDict()\n",
    "    imp_coord[\"week\"] = coords[\"days\"]\n",
    "    imp_coord[\"AG\"] = coords[\"AG\"]\n",
    "    imp_coord[\"BL\"] = coords[\"BL\"]\n",
    "    imported_mp = ModelParam(\"imported\",imp_coord,imported)\n",
    "    # Match population age-groups\n",
    "    \n",
    "    popAG,_,pop_coord = pop.Overlap(imported_mp,{\"AG\":\"left\"})\n",
    "    \n",
    "    \n",
    "    pm.Deterministic(\"imported\",imported)\n",
    "    pm.Deterministic(\"population\",popAG)\n",
    "    \n",
    "    # Dimensions = time x age x BL\n",
    "  #  pm.Deterministic(\"sum\",measures_daily+age_daily+BL_daily)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(\"parsing %.2f\"%(t1-t0))\n",
    "    #+adapt_diag\n",
    "    trace = pm.sample(init=\"advi+adapt_diag\",return_inferencedata=True,tune=400,draws=400,cores=4,chains=4,max_treedepth=12,target_accept=.95)\n",
    "    t2 = time.time()\n",
    "    print(\"toal %.1fs\"%(t2-t1))\n",
    "\n",
    "# advi 3.97, 103 total, season+measures\n",
    "# advi+adapt_diag 1.62, 107.8 total, seaoson+measures\n",
    "# advi 3.75, 51s sampling 166s total, season+measures+age\n",
    "# advi 1.92, 51s sampling 166s total, season+measures+age\n",
    "# BL as single Catmull 66.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace.posterior[\"season_sigma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = trace.posterior[\"measures_daily\"].quantile((0.5,.05,.95),[\"chain\",\"draw\"])\n",
    "\n",
    "plt.plot(coords[\"days\"],q[0])\n",
    "plt.fill_between(coords[\"days\"],q[1],q[2],alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = trace.posterior[\"age_daily\"][...,1,0].quantile((0.5,.05,.95),[\"chain\",\"draw\"])\n",
    "\n",
    "print(q.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.plot(coords[\"days\"],trace.posterior[\"age_daily\"][0,i,:,0,0])\n",
    "    plt.plot(coords[\"days\"],trace.posterior[\"age_daily\"][1,i,:,0,0],\"--\")\n",
    "\n",
    "plt.plot(coords[\"days\"],q[0])\n",
    "plt.fill_between(coords[\"days\"],q[1],q[2],alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = trace.posterior[\"R_eff\"].quantile((0.5,.05,.95),[\"chain\",\"draw\"])[...,1,1]\n",
    "print(q.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.semilogy(coords[\"days\"],trace.posterior[\"R_eff\"][0,i,:,0,0])\n",
    "    plt.semilogy(coords[\"days\"],trace.posterior[\"R_eff\"][1,i,:,0,0],\"--\")\n",
    "\n",
    "ax = plt.plot(coords[\"days\"],q[0])\n",
    "#plt.fill_between(coords[\"days\"],q[1],q[2],alpha=.1)\n",
    "\n",
    "plt.ylim([.01,300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = trace.posterior[\"BL_daily\"][...,0,0].quantile((0.5,.05,.95),[\"chain\",\"draw\"])\n",
    "\n",
    "print(q.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.plot(coords[\"days\"],trace.posterior[\"BL_daily\"][0,i,:,0,0])\n",
    "    plt.plot(coords[\"days\"],trace.posterior[\"BL_daily\"][1,i,:,0,0],\"--\")\n",
    "\n",
    "plt.plot(coords[\"days\"],q[0])\n",
    "plt.fill_between(coords[\"days\"],q[1],q[2],alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-starter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [\"measures_daily\",\"age_daily\",\"BL_daily\",\"R_eff\",\"imported\",\"population\"]:\n",
    "    print(k,trace.posterior[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = trace.posterior[\"imported\"][0,0]\n",
    "r = trace.posterior[\"R_eff\"][0,0]\n",
    "\n",
    "print(i.shape)\n",
    "print(r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_lognormal(x, mu, sigma):\n",
    "# Limit to prevent NANs\n",
    "    x = tt.clip(x,1e-9,1e12)\n",
    "    sigma = tt.clip(sigma,1e-9,1e12)\n",
    "    mu = tt.clip(mu,1e-9,1e12)\n",
    "    \n",
    "    distr = 1/x * tt.exp( -( (tt.log(x) - mu) ** 2) / (2 * sigma ** 2))\n",
    "    return distr / (tt.sum(distr, axis=0) + 1e-12)\n",
    "\n",
    "def SEIR_model(N, imported_t,Reff_t, median_incubation,sigma_incubation,l=32):\n",
    "    N = tt.cast(N,'float64')\n",
    "    beta = tt_lognormal(tt.arange(l), tt.log(median_incubation), sigma_incubation)\n",
    "    \n",
    "    # Dirty hack to prevent nan - seems not needed if priors are better\n",
    " #   beta = tt.alloc(0,l)\n",
    "  #  beta = tt.set_subtensor(beta[tt.clip(tt.cast(median_incubation,'int32'),1,l-2)],1)\n",
    "     \n",
    "    Reff_t = tt.as_tensor_variable(Reff_t)\n",
    "    imported_t = tt.as_tensor_variable(imported_t)\n",
    "\n",
    "    def new_day(Reff_at_t,imported_at_t,infected,E_t,beta,N):\n",
    "        f = E_t / N\n",
    "     #   f = 1\n",
    "        new = imported_at_t + tt.dot(infected,beta) * Reff_at_t * f\n",
    "        new = tt.clip(new,0,N)\n",
    "     \n",
    "        infected = tt.roll(infected,1,0)\n",
    "        infected = tt.set_subtensor(infected[:1],new,inplace=False)\n",
    "        E_t = tt.clip(E_t-new,0,E_t)\n",
    "#        E_t = E_t-new\n",
    "        return new,infected,E_t\n",
    "    \n",
    "    outputs_info = [None,np.zeros(l),N]\n",
    "    infected_t,updates = theano.scan(fn=new_day,\n",
    "                                     sequences=[Reff_t,imported_t],\n",
    "                                     outputs_info=outputs_info,\n",
    "                                     non_sequences=[beta,N],\n",
    "                                     profile=False)\n",
    "                                     \n",
    "    return infected_t\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-violation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-november",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-transportation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-valuation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
